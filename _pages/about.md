---
layout: about
title: About
permalink: /
description: 

profile:
  align: right
  image: me.jpg
  address: 

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Senior Researcher, Tencent<br>
xing.tang [at] hotmail.com, shawntang [at] tencent.com<br>
[Google scholar](https://scholar.google.com/citations?user=hBZ_tKsAAAAJ) | [DBLP](https://dblp.org/pid/19/2969-1.html) | [Github](https://github.com/jindongwang) || [Twitter](https://twitter.com/jd92wang) | [Zhihu](https://www.zhihu.com/people/jindongwang) | [Wechat](http://jd92.wang/assets/img/wechat_public_account.jpg) | [Bilibili](https://space.bilibili.com/477087194) || [CV](https://go.jd92.wang/cv) [CV (Chinese)](https://go.jd92.wang/cvchinese)

Dr. Xing Tang is currently a Senior Researcher at Tencent. He obtained his Ph.D from Computer Science, Xidian University in 2019. He visited Qiang Yangâ€™s group at Hong Kong University of Science and Technology in 2018. His research interest includes robust machine learning, transfer learning, semi-supervised learning, and federated learning. He has published over 50 papers with 6900 citations at leading conferences and journals such as ICLR, NeurIPS, TKDE, TASLP etc. He has 6 highly cited papers in [Google Scholar metrics](https://www.aminer.cn/ai2000?domain_ids=5dc122672ebaa6faa962c2a4). His paper "FedHealth" received the best application paper award at IJCAI FL workshop and it is the most cited paper among all federated learning for healthcare papers. He also received other awards including best paper award at ICCSE'18 and the prestigous excellent Ph.D thesis award (only 1 at ICT each year). In 2022 and 2023, he was selected as one of the [AI 2000 Most Influential Scholars](https://www.aminer.cn/ai2000?domain_ids=5dc122672ebaa6faa962c2a4) by AMiner between 2012-2022. He serves as the senior program committee member of IJCAI and AAAI, and PC members for top conferences like ICML, NeurIPS, ICLR, CVPR etc. He opensourced several projects to help build a better community, such as transferlearning, torchSSL, USB, personalizedFL, and robustlearn, which received over 12K stars on Github. He published a textbook [Introduction to Transfer Learning](http://jd92.wang/tlbook) to help starters quickly learn transfer learning. He gave tutorials at [IJCAI'22](https://dgresearch.github.io/), [WSDM'23](https://dgresearch.github.io/), and [KDD'23](https://mltrust.github.io/).

**Research interest:** robust machine learning, out-of-distribution / domain generalization, transfer learning, semi-supervised learning, federated learning, and related applications such as activity recognition and computer vision. These days, I'm particularly interested in Large Language Models (LLMs) [evaluation](https://llm-eval.github.io/) and [robustness enhancement](https://llm-enhance.github.io/). See this [page](https://jd92.wang/research/) for more details. *Interested in [internship](https://zhuanlan.zhihu.com/p/102558267) or collaboration? Contact me.*

**Announcement:** I'm experimenting a new form of research collaboration. You can click [here](https://forms.office.com/r/32Fs6uAjT6) if you are interested!


